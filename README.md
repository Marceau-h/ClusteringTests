# Les corpus

## 3 langues
* corpus --> corpus franÃ§ais
* corpus_en --> corpus anglais
* corpus_pt --> corpus portugais

## Architecture dossier

* Un dossier par auteur ; 
* Pour chaque auteur : 
 * un dossier REF avec le texte de rÃ©fÃ©rence et les clusters d'entitÃ©s nommÃ©es de lieu ;
 * un dossier OCR : 1 dossier par OCR. Dans chacun le texte OCR et les cluster d'entitÃ©s nommÃ©es de lieu ; 
 
# Cluster

Nous avons utilisÃ© plusieurs algorithme de clustering dont les noms figurent dans le noms de fichiers :
 
* AffpropDistA1_clusters
* AffpropHyperparams2_clusters
* AffpropHyperparams_clusters
* AffpropKeepVectors_clusters
* DBScan_clusters
* Default_clusters
* HDBScan_clusters
* KMeans_clusters
* Optics_clusters.

Les fichiers qui se terminent par :
* *cluster.json comportent un dictionnaire des clusters, dont les clÃ©s sont le numÃ©ro du cluster et la valeur la liste des termes du cluster ;
* *corr.csv et * *cor.jsonl sont des fichiers pour l'annotation en vue de l'Ã©valuation des clusters.

## Notes Ã  propos des algorithmes de clustering utilisÃ©s :

* AffinitÃ© propagation : Affprop default :
 * le centroÃ¯de dans Affprop est calculÃ© en rÃ©duisant la dimension a deux et calcul de la moyenne de tous les x et de tous les y ;
 * test de diffÃ©rents paramÃ©trages ;
* hyperparam : changer les hyperparamÃ¨tres ;
* DistA1 : distance a 1 si moins de 2 ngral en communs ;
* KeepVectors : dÃ¨s quâ€™il y a moins de 1 3grammes en commun il vont dans cluster-1 ;
* SbBscan : plus proche voisin agglomÃ©ratif ;

### Ce qui nous a convaincu :
* Affpropohyperparams2 :  Dans le CountVectorizer paramÃ©trage du min_df = 3 pour que seul les bigrammes et trigrammes prÃ©sent dans plus 2 tokens â€“> tous les tokens avec 0 colonnes -> hors clustering ğŸ™‚âœ… ğŸ‰


### Finalement nous avons laissÃ© de cÃ´tÃ©:
 * Dendrogramme Hierarchical Bisecting K-means, il faut donner un nombre de cluster et du coup tout Ã©tÃ© dans le mÃªme cluster. Il a tournÃ© sur un K de 2 Ã  20 et conservation du meilleur silhouette-score  âŒ 
 * OPTICS â†’ utiliser une distance cosinus
 * DBscan â†’ utiliser une distance cosinus
 * compter le nb de bigramme et envoyer Ã  lâ€™algo si $bigramme < 2$ -> mettre la distance Ã  1 âŒ

# Annotation manuelle pour l'Ã©valuation du clustering :

## Fichiers annotÃ©s
Les fichiers dont le nom se termine par corr-annot-OK.csv sont rÃ©-annotÃ©s manuellement pour l'Ã©valuation du clustering.

* Dans le dossier corpus : AIMARD-TRAPPEURS ;
* Dans corpus\_en : AGUILAR\_home-influence ;

## Description du fichier annotÃ©
* La colonne text comporte les mots du cluster ligne par ligne ;
* La colonne cluster comporte le numÃ©ro du cluster attribuÃ© lors du calcul des clusters ;
* La colonne cluster_corrected comporte le numÃ©ro du cluster ;

* Retirer des clusters quand dans la cellule il nâ€™y a que  : 
 * des nombres/chiffres, mettre dans le cluster -1
 * suite de bi-tri-grammes de caractÃ¨re qui se suivent plus de 2*, -1

## Consignes pour l'annotation des clusters

* des ponctuations qui se suivent : â€¦,,.., poubelle
 * plusieurs fois le mÃªme caractÃ¨re unique  qui se suit (ccc), \w{2,} poubelle
 * les mots de 1 caractÃ¨res paramÃ©trage utilisateur
 * un mÃ©lange de minucules, majuscules, nombre, chiffres, ponctuations


* Signes annotations : 

 * â€œ ?â€ quand je ne vois pas pourquoi le terme fait parti du cluster mais que jâ€™ai un doute
 * â€œâ€˜  â€œ quand le mot ne devrait pas faire partie du cluster selon moi
 * â€œ $â€  indique un problÃ¨me dans l â€˜annotation du csv origine
 * -1 quand câ€™est pas une entitÃ© et quâ€™il est tout seul



limite de lâ€™affinitÃ© de propagation : des mots sont mis dans le mÃªme cluster  alors quâ€™ils ne semblent pas avoir de bi-tri-gr commun, câ€™est parcequâ€™ils ont un bi-tri-gr commun avec un troisiÃ¨me




